{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca12ca3",
   "metadata": {},
   "source": [
    "### Labolatorium 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51660c",
   "metadata": {},
   "source": [
    "1. Utworzenie SparkSession i prostego DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9588833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+\n",
      "|  dzial|   imie|wiek|\n",
      "+-------+-------+----+\n",
      "|Finanse|   Adam|  30|\n",
      "|     IT|    Ewa|  26|\n",
      "|     PR| Damian|  25|\n",
      "|     IT|Mariusz|  35|\n",
      "+-------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, desc, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current_python = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = current_python\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = current_python\n",
    "os.environ['HADOOP_HOME'] = \"C:\\\\hadoop\"\n",
    "sys.path.append(\"C:\\\\hadoop\\\\bin\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Lab1\").getOrCreate()\n",
    "data = [{\"imie\": \"Adam\", \"wiek\": 30, \"dzial\": \"Finanse\"},\n",
    "        {\"imie\": \"Ewa\", \"wiek\": 26, \"dzial\": \"IT\"},\n",
    "        {\"imie\": \"Damian\", \"wiek\": 25, \"dzial\": \"PR\"},\n",
    "        {\"imie\": \"Mariusz\", \"wiek\": 35, \"dzial\": \"IT\"}]\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a55085",
   "metadata": {},
   "source": [
    "2. Wczytanie danych z pliku CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3eee3b5-a160-46a0-a5bc-03638676d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|age|department|\n",
      "+-----+---+----------+\n",
      "|  Jan| 28|        IT|\n",
      "| Anna| 34|        HR|\n",
      "|Piotr| 22|   Finance|\n",
      "|  Ewa| 45|        IT|\n",
      "|Marek| 31|        HR|\n",
      "+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.csv(\"pracownicy.csv\", header=True, inferSchema=True)\n",
    "df_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe5d9e-60ec-4f74-a3c4-ee7a6e4e2bcc",
   "metadata": {},
   "source": [
    "3. Filtrowanie i wybór kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc0a689-2306-42f9-83fa-f75ba24b888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| Anna| 34|\n",
      "|  Ewa| 45|\n",
      "|Marek| 31|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_csv.select(\"name\", \"age\").filter(df_csv.age > 30)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0140f-e249-46c6-88eb-c9f5747dea93",
   "metadata": {},
   "source": [
    "4. Sortowanie i agregacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae94073-4c11-416c-84bc-42a82d4028fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|department|\n",
      "+------+---+----------+\n",
      "|   Ewa| 45|        IT|\n",
      "|  Anna| 34|        HR|\n",
      "| Marek| 31|        HR|\n",
      "|Joanna| 29|   Finance|\n",
      "|   Jan| 28|        IT|\n",
      "| Piotr| 22|   Finance|\n",
      "+------+---+----------+\n",
      "\n",
      "+----------+-------+\n",
      "|department|avg_age|\n",
      "+----------+-------+\n",
      "|        HR|   32.5|\n",
      "|   Finance|   25.5|\n",
      "|        IT|   36.5|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df_csv.orderBy(col(\"age\").desc())\n",
    "df_sorted.show()\n",
    "df_grouped = df_csv.groupBy(\"department\").agg(avg(\"age\").alias(\"avg_age\"))\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a12d49-eccb-4dfe-ae87-a0ab173667d3",
   "metadata": {},
   "source": [
    "5. Dodanie i usunięcie kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd61fdbf-7634-4da2-bc63-62d6b65bb382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+--------------+\n",
      "|  name|age|department|age_in_5_years|\n",
      "+------+---+----------+--------------+\n",
      "|   Jan| 28|        IT|            33|\n",
      "|  Anna| 34|        HR|            39|\n",
      "| Piotr| 22|   Finance|            27|\n",
      "|   Ewa| 45|        IT|            50|\n",
      "| Marek| 31|        HR|            36|\n",
      "|Joanna| 29|   Finance|            34|\n",
      "+------+---+----------+--------------+\n",
      "\n",
      "+------+---+--------------+\n",
      "|  name|age|age_in_5_years|\n",
      "+------+---+--------------+\n",
      "|   Jan| 28|            33|\n",
      "|  Anna| 34|            39|\n",
      "| Piotr| 22|            27|\n",
      "|   Ewa| 45|            50|\n",
      "| Marek| 31|            36|\n",
      "|Joanna| 29|            34|\n",
      "+------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_plus_5 = df_csv.withColumn(\"age_in_5_years\", col(\"age\") + 5)\n",
    "df_plus_5.show()\n",
    "\n",
    "df_no_dept = df_plus_5.drop(\"department\")\n",
    "df_no_dept.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b411f15-26d6-42b7-a3b9-36ef1c4d48b4",
   "metadata": {},
   "source": [
    "6. Łączenie dwóch DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4897dff-5fe9-4e6a-8fb0-0d9f107b13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|projects|\n",
      "+------+--------+\n",
      "|   Jan|       5|\n",
      "|  Anna|       3|\n",
      "| Piotr|       4|\n",
      "|   Ewa|       7|\n",
      "| Marek|       2|\n",
      "|Joanna|       6|\n",
      "+------+--------+\n",
      "\n",
      "+------+---+----------+--------+\n",
      "|  name|age|department|projects|\n",
      "+------+---+----------+--------+\n",
      "|   Jan| 28|        IT|       5|\n",
      "|  Anna| 34|        HR|       3|\n",
      "| Piotr| 22|   Finance|       4|\n",
      "|   Ewa| 45|        IT|       7|\n",
      "| Marek| 31|        HR|       2|\n",
      "|Joanna| 29|   Finance|       6|\n",
      "+------+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv_projects = spark.read.csv(\"projekty.csv\", header=True, inferSchema=True)\n",
    "df_csv_projects.show()\n",
    "\n",
    "df_joined = df_csv.join(df_csv_projects, on=\"name\", how=\"inner\")\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39657e8-e43e-406c-92c6-617c8b133501",
   "metadata": {},
   "source": [
    "7. Obsługa brakujących wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c799bb2d-0f70-4a29-a90d-556c1e87a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+\n",
      "| name| age|department|\n",
      "+-----+----+----------+\n",
      "|Kamil|NULL|        IT|\n",
      "| NULL|  25|        HR|\n",
      "|Basia|  30|      NULL|\n",
      "+-----+----+----------+\n",
      "\n",
      "+-----+---+----------+\n",
      "| name|age|department|\n",
      "+-----+---+----------+\n",
      "|Kamil|  0|        IT|\n",
      "| Brak| 25|        HR|\n",
      "|Basia| 30|      Brak|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_nulls = [\n",
    "    (\"Kamil\", None, \"IT\"),\n",
    "    (None, 25, \"HR\"),\n",
    "    (\"Basia\", 30, None)\n",
    "]\n",
    "df_with_nulls = spark.createDataFrame(data_nulls, [\"name\", \"age\", \"department\"])\n",
    "df_with_nulls.show()\n",
    "\n",
    "df_filled = df_with_nulls.na.fill({\n",
    "    \"age\": 0, \n",
    "    \"name\": \"Brak\", \n",
    "    \"department\": \"Brak\"\n",
    "})\n",
    "\n",
    "\n",
    "df_filled.show()\n",
    "df_dropped_nulls = df_with_nulls.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c8b76-efbb-4a9f-a36d-97c218133069",
   "metadata": {},
   "source": [
    "8. Operacje na oknach (Window Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f7137ad-77c4-42fe-8bf9-6be401fa8b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+--------+----+\n",
      "|  name|age|department|projects|rank|\n",
      "+------+---+----------+--------+----+\n",
      "|   Ewa| 45|        IT|       7|   1|\n",
      "|Joanna| 29|   Finance|       6|   2|\n",
      "|   Jan| 28|        IT|       5|   3|\n",
      "| Piotr| 22|   Finance|       4|   4|\n",
      "|  Anna| 34|        HR|       3|   5|\n",
      "| Marek| 31|        HR|       2|   6|\n",
      "+------+---+----------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.orderBy(col(\"projects\").desc())\n",
    "df_ranked = df_joined.withColumn(\"rank\", rank().over(windowSpec))\n",
    "df_ranked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7f895-3fd1-4041-a3d6-85615e5ffe1e",
   "metadata": {},
   "source": [
    "9. Operacje na RDD - klasyczne liczenie słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3656b741-8910-482a-aa27-ecc9ab10e25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('To', 3), ('jest', 2), ('do', 2), ('jak', 2), ('tekst', 2), ('przykładowy', 1), ('liczenia', 1), ('słów.', 1), ('ćwiczenie', 1), ('działa', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"tekst_do_liczenia.txt\")\n",
    "\n",
    "counts = rdd.flatMap(lambda line: line.split(\" \")) \\\n",
    "            .map(lambda word: (word, 1)) \\\n",
    "            .reduceByKey(lambda a, b: a + b) \\\n",
    "            .takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea72545-af11-4325-af13-e2ac223c22d9",
   "metadata": {},
   "source": [
    "10. Zapisywanie wyników do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d21e54a2-0cf9-400d-9b30-c6e2d963fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked.write.csv(\"wyniki.csv\", header=True)\n",
    "df_ranked.write.json(\"wyniki.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c719d6-8d2c-40b5-92d3-cf073c96dd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Spark Lab)",
   "language": "python",
   "name": "spark_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
